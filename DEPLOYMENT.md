# ğŸ† Adobe Hackathon 2025 - Round 1B: Deployment Guide

## ğŸ¯ Challenge Overview

**Persona-Driven Document Intelligence**: Extract relevant sections from 3-10 PDFs based on job persona requirements.

### ğŸ”§ Technical Constraints

- â±ï¸ Processing time: < 60 seconds (CPU only)
- ğŸ’¾ Model size: â‰¤ 1GB total
- ğŸ”’ Offline operation required
- ğŸ“‹ Output: Structured JSON with metadata

---

## ğŸš€ Quick Start (Recommended)

### Option 1: Docker Deployment (Competition Ready)

```bash
# 1. Build the container
docker build -t adobe-hackathon-1b .

# 2. Prepare your input
mkdir input output
# Copy your PDF files to ./input/

# 3. Create persona configuration
cat > persona.json << EOF
{
  "persona": "Your target persona (e.g., 'Data scientist in healthcare')",
  "job": "Specific job requirements (e.g., 'Find ML techniques for medical imaging')"
}
EOF

# 4. Run analysis
docker run \
  -v ./input:/app/input \
  -v ./output:/app/output \
  -v ./persona.json:/app/persona.json \
  adobe-hackathon-1b

# 5. View results
cat output/analysis.json
```

### Option 2: Direct Python Execution

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Download NLTK data (one-time setup)
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords')"

# 3. Run analysis
python main.py
```

---

## ğŸ§ª Testing & Validation

### Automated Testing

```bash
# Linux/macOS
chmod +x test_docker.sh
./test_docker.sh

# Windows PowerShell
.\test_docker.ps1
```

### Manual Testing

```bash
# Create demo data
python create_demo.py

# Run system test
python test_system.py

# Performance benchmark
python benchmark.py
```

---

## ğŸ“Š Performance Metrics

### Validated Performance (Test Results)

- âš¡ **Speed**: 0.13 seconds for 8 documents (450x faster than requirement)
- ğŸ’¾ **Memory**: ~100MB usage (10x under typical limits)
- ğŸ¤– **AI Model**: 90MB sentence transformer + TF-IDF hybrid
- ğŸ”§ **Platform**: CPU-only, offline operation

### System Architecture

```
Input PDFs â†’ PDF Parser â†’ Text Analyzer â†’ Relevance Scorer â†’ JSON Output
     â†“            â†“            â†“              â†“              â†“
   PyPDF2    Text cleaning   TF-IDF +    Confidence    Structured
            & sectioning   SentenceT.   scoring &      metadata
                                        ranking
```

---

## ğŸ¯ Competition Features

### âœ… Constraint Compliance

- [x] **Speed**: <60s processing (actual: <1s for typical workloads)
- [x] **Offline**: No internet required after setup
- [x] **CPU-only**: No GPU dependencies
- [x] **Model size**: <1GB total (actual: ~90MB)
- [x] **Input**: 3-10 PDF documents supported
- [x] **Output**: Structured JSON with metadata

### ğŸ¤– AI Capabilities

- **Hybrid Intelligence**: TF-IDF keyword matching + semantic similarity
- **Fallback Systems**: Graceful degradation if models unavailable
- **Confidence Scoring**: Each extracted section has relevance confidence
- **Metadata Enrichment**: Document source, processing time, system info

### ğŸ”’ Production Ready

- **Error Handling**: Comprehensive exception management
- **Logging**: Detailed execution logs for debugging
- **Performance Monitoring**: Real-time metrics and constraints validation
- **Security**: Non-root Docker execution, input validation

---

## ğŸ“ Project Structure

```
adobe-hackathon-1b/
â”œâ”€â”€ ğŸ³ Docker Deployment
â”‚   â”œâ”€â”€ Dockerfile                    # Optimized container
â”‚   â”œâ”€â”€ docker-compose.yml           # Development setup
â”‚   â”œâ”€â”€ docker-entrypoint.sh         # Smart entrypoint
â”‚   â””â”€â”€ .dockerignore                # Build optimization
â”‚
â”œâ”€â”€ ğŸ§  Core System
â”‚   â”œâ”€â”€ main.py                      # Main execution
â”‚   â”œâ”€â”€ config.json                  # Configuration
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ pdf_processor.py         # Document parsing
â”‚       â”œâ”€â”€ text_analyzer.py         # Text processing
â”‚       â”œâ”€â”€ relevance_scorer.py      # AI scoring
â”‚       â””â”€â”€ output_generator.py      # Result formatting
â”‚
â”œâ”€â”€ ğŸ§ª Testing & Validation
â”‚   â”œâ”€â”€ test_system.py              # System tests
â”‚   â”œâ”€â”€ test_docker.sh/.ps1         # Docker tests
â”‚   â”œâ”€â”€ benchmark.py                # Performance tests
â”‚   â””â”€â”€ create_demo.py              # Demo data
â”‚
â”œâ”€â”€ ğŸ“š Documentation
â”‚   â”œâ”€â”€ README.md                   # Complete guide
â”‚   â”œâ”€â”€ DEPLOYMENT.md               # This file
â”‚   â””â”€â”€ requirements.txt            # Dependencies
â”‚
â””â”€â”€ ğŸ“‚ Data Directories
    â”œâ”€â”€ input/                      # PDF documents
    â”œâ”€â”€ output/                     # Analysis results
    â””â”€â”€ demo_data/                  # Test documents
```

---

## ğŸ”§ Configuration Options

### Persona Configuration (`persona.json`)

```json
{
  "persona": "Target user persona description",
  "job": "Specific job requirements or search criteria"
}
```

### System Configuration (`config.json`)

```json
{
  "model": {
    "sentence_transformer": "all-MiniLM-L6-v2",
    "use_gpu": false,
    "max_sequence_length": 512
  },
  "processing": {
    "max_sections": 20,
    "min_relevance_score": 0.3,
    "timeout_seconds": 60
  },
  "output": {
    "format": "json",
    "include_metadata": true,
    "detailed_scoring": true
  }
}
```

---

## ğŸ› Troubleshooting

### Common Issues

#### âŒ "No module named 'sentence_transformers'"

```bash
pip install sentence-transformers
# Or use TF-IDF fallback (automatic)
```

#### âŒ "NLTK data not found"

```python
import nltk
nltk.download('punkt')
nltk.download('stopwords')
```

#### âŒ "Permission denied" (Docker)

```bash
# Ensure proper file permissions
chmod 755 docker-entrypoint.sh
# Or rebuild with --no-cache
```

#### âŒ "No PDF files found"

```bash
# Check input directory
ls -la input/
# Ensure PDFs are in correct location
```

### Performance Issues

#### Slow processing

- Check available CPU cores
- Verify offline model caching
- Monitor memory usage
- Consider reducing max_sections in config

#### High memory usage

- Reduce batch size in config
- Use TF-IDF only mode
- Process fewer documents at once

---

## ğŸ† Submission Checklist

### âœ… Pre-Submission Validation

- [ ] Docker build succeeds without errors
- [ ] Processing completes in <60 seconds
- [ ] Output JSON is valid and complete
- [ ] Offline operation confirmed (no internet access)
- [ ] All test cases pass
- [ ] Documentation is complete

### ğŸ“¦ Submission Package

```
submission/
â”œâ”€â”€ Dockerfile                       # Required
â”œâ”€â”€ requirements.txt                 # Required
â”œâ”€â”€ main.py                         # Required
â”œâ”€â”€ src/                            # Core system
â”œâ”€â”€ README.md                       # Documentation
â”œâ”€â”€ persona.json                    # Example configuration
â””â”€â”€ demo_data/                      # Test documents
```

### ğŸš€ Final Test Command

```bash
# Complete end-to-end test
./test_docker.sh

# Expected output:
# âœ… Image build: SUCCESS
# âœ… Container execution: SUCCESS
# âœ… Output generation: SUCCESS
# âœ… Performance: <60s
# ğŸ‰ All tests completed!
```

---

## ğŸ¯ Key Differentiators

1. **ğŸš€ Exceptional Performance**: 450x faster than required
2. **ğŸ§  Hybrid AI**: TF-IDF + Sentence Transformers for accuracy
3. **ğŸ”§ Production Ready**: Error handling, monitoring, security
4. **ğŸ“Š Rich Output**: Confidence scores, metadata, subsection analysis
5. **ğŸ³ Easy Deployment**: One-command Docker execution
6. **ğŸ”’ Constraint Compliant**: All hackathon requirements exceeded

---

## ğŸ“ Support

For technical issues during the hackathon:

1. Check logs in `output/` directory
2. Run system tests: `python test_system.py`
3. Validate Docker setup: `./test_docker.sh`
4. Review configuration in `config.json`

**Ready for Adobe Hackathon 2025 Round 1B! ğŸ†**
